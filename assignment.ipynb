{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2, \n",
    "### Identify the main people, organisations, and sources mentioned on the Volkswagen emissions scandal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import glob\n",
    "import gzip\n",
    "import codecs\n",
    "import re\n",
    "import sys \n",
    "import os\n",
    "import json\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify enities and their relations using corenlp tool\n",
    "\n",
    "In this experiments, I will use corenlp tool for identifying entities and their relations in the text. Corenlp tool has traind models for entity recognition and KBP relation extraction. To do that, first we have to download the corenlnp tool from https://stanfordnlp.github.io/CoreNLP/download.html and then we can start the corenlp server in the terminal using following command\n",
    "\n",
    "java -mx8g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators tokenize, ssplit, pos, lemma, parse, relation -port 9000 -timeout 30000\n",
    "\n",
    "\n",
    "In following block, I have defined three functions to extract named enities and their relations from text using corenlp server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "def get_token_ner(text):\n",
    "\tinput_string = text  \n",
    "\tif isinstance(input_string, str):\n",
    "\t\tinput_string = input_string.decode('ascii', 'ignore').encode('ascii')\n",
    "\telif isinstance(input_string, unicode):\n",
    "\t\tinput_string = input_string.encode('ascii', 'ignore')\n",
    "\ttext = input_string\n",
    "\n",
    "\toutput = nlp.annotate(text, properties={ 'annotators': 'ner, relation', 'outputFormat': 'json'} )\n",
    "\n",
    "\ttokens = [ t['originalText'] for i in range(len(output) ) for t in output[\"sentences\"][i][\"tokens\"] ]\t\t\n",
    "\n",
    "\tner_list = [ (ner['text'], ner['ner'], ner['tokenBegin'], ner['tokenEnd'] ) for i in range(len(output) ) for ner in output['sentences'][i]['entitymentions']] \n",
    "\n",
    "\treturn tokens, ner_list\n",
    "\n",
    "\n",
    "def get_kbp_relation(text):\n",
    "    input_string = text  \n",
    "    if isinstance(input_string, str):\n",
    "        input_string = input_string.decode('ascii', 'ignore').encode('ascii')\n",
    "    elif isinstance(input_string, unicode):\n",
    "        input_string = input_string.encode('ascii', 'ignore')\n",
    "    text = input_string\n",
    "    \n",
    "    output = nlp.annotate(text, properties={\"annotators\": \"kbp\", \"outputFormat\": \"json\",  })\n",
    "    rel_list = [ (rel['subject'], rel['relation'], rel['object']) for rel in output['sentences'][0]['kbp'] ]\n",
    "    return rel_list\n",
    "\n",
    "\n",
    "\n",
    "def get_relation(text):\n",
    "\n",
    "\tinput_string = text  \n",
    "\tif isinstance(input_string, str):\n",
    "\t\tinput_string = input_string.decode('ascii', 'ignore').encode('ascii')\n",
    "\telif isinstance(input_string, unicode):\n",
    "\t\tinput_string = input_string.encode('ascii', 'ignore')\n",
    "\ttext = input_string\n",
    "\n",
    "\n",
    "\tnlp=StanfordCoreNLP(\"http://localhost:9001/\")\n",
    "\toutput = nlp.annotate(text, properties={\"annotators\":\"tokenize,ssplit,pos,depparse,natlog,openie\", \"outputFormat\": \"json\",\"openie.triple.strict\":\"true\", \"openie.max_entailments_per_clause\":\"1\"})\n",
    "\tresult = [output[\"sentences\"][0][\"openie\"] for item in output]\n",
    "\n",
    " \n",
    "\trelationSent = []\n",
    "\tfor i in result:\n",
    "\t\tfor rel in i:\n",
    "\t\t\trelationSent.append( (rel['relation'], rel['subject'], rel['object'] ) )\n",
    "\n",
    "            \n",
    "\treturn relationSent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the documents which are not relavent and extract  entities and relations on filtered texts\n",
    "\n",
    "For this experiment, we consider all articles which present 'Volkswagen' and 'scandal' or 'emissions' in the text. In order to identify the main people and organisations involved in the scandal, we make entity recognition in each sentence of the filtered articles and all the sentences where at least one person name and one organizaton name are present we use relation extraction model predict relation on that sentence.\n",
    "\n",
    "\n",
    "Following are the examples of few relation instance we obtained with the experiments;\n",
    "\n",
    "Source:Malay Mail\t Rel:Martin Winterkorn||per:employee_or_member_of||VW\t\n",
    "Source:Malay Mail\t Rel:VW||org:top_members_employees||Martin Winterkorn\t\n",
    "Source:Malay Mail\t Rel:Christian Stadler||per:employee_or_member_of||Volkswagen\t\n",
    "Source:Charlotte Observer\t rel:Volkswagen||org:top_members_employees||Herbert Diess\n",
    "\n",
    "\n",
    "Here, from source 'Malay Mail', we obatained that 'Martin Winterkorn' is a high-ranking-employee and 'Christian Stadler' is an employee of Valkswagen organization. \n",
    "\n",
    "Also source 'Charlotte Observer', written 'Herbert Diess' is an emplyee of 'Valkswagen' organization\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:Malay Mail\t Rel:Martin Winterkorn||per:employee_or_member_of||VW\t\n",
      "Source:Malay Mail\t Rel:VW||org:top_members_employees||Martin Winterkorn\t\n",
      "Source:Malay Mail\t Rel:Christian Stadler||per:employee_or_member_of||Volkswagen\t\n",
      "Source:Charlotte Observer\t Rel:Volkswagen||org:top_members_employees||Herbert Diess\t\n",
      "Source:Charlotte Observer\t Rel:Herbert Diess||per:employee_or_member_of||Volkswagen\t\n",
      "Source:Charlotte Observer\t Rel:Volkswagen||org:top_members_employees||Winfried Vahland\t\n",
      "Source:Charlotte Observer\t Rel:Volkswagen||org:top_members_employees||Matthias Mueller\t\n",
      "Source:Charlotte Observer\t Rel:Matthias Mueller||per:employee_or_member_of||Volkswagen\t\n",
      "Source:Charlotte Observer\t Rel:Volkswagen||org:country_of_headquarters||U.S.\t\n",
      "Source:Charlotte Observer\t Rel:Volkswagen||org:top_members_employees||Mueller\t\n",
      "Source:TheStar.com.my\t Rel:Martin Winterkorn||per:employee_or_member_of||Volkswagen\t\n",
      "Source:TheStar.com.my\t Rel:Volkswagen||org:top_members_employees||Martin Winterkorn\t\n",
      "Source:ADVFN India\t Rel:Dobrindt||per:employee_or_member_of||Volkswagen\t\n",
      "Source:WTAQ News Talk\t Rel:Volkswagen||org:top_members_employees||Matthias Muller\t\n",
      "Source:WTAQ News Talk\t Rel:Matthias Muller||per:employee_or_member_of||Volkswagen\t\n",
      "Source:MyInforms\t Rel:Volkswagen||org:top_members_employees||Mike Jackson\t\n",
      "Source:Star 96\t Rel:VW||org:top_members_employees||Matthias Mueller\t\n",
      "Source:Star 96\t Rel:Matthias Mueller||per:employee_or_member_of||VW\t\n",
      "Source:Star 96\t Rel:Winterkorn||per:employee_or_member_of||VW\t\n",
      "Source:Star 96\t Rel:Mueller||per:employee_or_member_of||VW\t\n",
      "Source:Star 96\t Rel:Herbert Diess||per:employee_or_member_of||VW\t\n",
      "Source:Star 96\t Rel:Rupert Stadler||per:employee_or_member_of||VW\t\n",
      "Source:Eye Witness News\t Rel:Volkswagen||org:city_of_headquarters||WOLFSBURG\t\n",
      "Source:Eye Witness News\t Rel:Volkswagen||org:country_of_headquarters||United States\t\n",
      "Source:Business Plus Online\t Rel:Volkswagen||org:top_members_employees||he\t\n",
      "Source:Kenly News\t Rel:Heinz-Jakob Neusser||per:employee_or_member_of||VW\t\n",
      "Source:Kenly News\t Rel:VW||org:top_members_employees||Heinz-Jakob Neusser\t\n",
      "Source:Kenly News\t Rel:Winterkorn||per:employee_or_member_of||Volkswagen\t\n",
      "Source:Business News Network\t Rel:Carl Hahn||per:employee_or_member_of||VW\t\n",
      "Source:ADVFN UK\t Rel:Volkswagen||org:top_members_employees||Ferdinand Piech\t\n",
      "Source:ADVFN UK\t Rel:Ferdinand Piech||per:employee_or_member_of||Volkswagen\t\n",
      "Source:ADVFN UK\t Rel:Volkswagen||org:top_members_employees||Hans-Dieter Potsche\t\n",
      "Source:ADVFN UK\t Rel:Volkswagen||org:top_members_employees||Piech\t\n",
      "Source:ADVFN UK\t Rel:Hans-Dieter Potsche||per:employee_or_member_of||Volkswagen\t\n",
      "Source:Economic Times\t Rel:Volkswagen||org:top_members_employees||Oliver Blume\t\n",
      "Source:Economic Times\t Rel:VW||org:subsidiaries||Audi\t\n",
      "Source:Economic Times\t Rel:VW||org:top_members_employees||Blume\t\n",
      "Source:Economic Times\t Rel:Blume||per:employee_or_member_of||Volkswagen\t\n",
      "Source:Economic Times\t Rel:Blume||per:employee_or_member_of||VW\t\n",
      "Source:Economic Times\t Rel:VW||org:top_members_employees||Wolfgang Hatz\t\n",
      "Source:Barry and District News\t Rel:Alexander Dobrindt||per:employee_or_member_of||VW\t\n",
      "Source:Gnom.es\t Rel:Volkswagen||org:top_members_employees||Winterkorn\t\n",
      "Source:CityNews.ca\t Rel:Lancaster||per:employee_or_member_of||Volkswagen\t\n",
      "Source:newsghana.com.gh\t Rel:Volkswagen||org:country_of_headquarters||German\t\n",
      "Source:Yorkshire Coast Radio\t Rel:Clifford||per:employee_or_member_of||VW\t\n",
      "Source:Spy Ghana\t Rel:Arndt Ellinghorst||per:employee_or_member_of||VW\t\n",
      "Source:Expressions of Daily Life\t Rel:Mueller||per:employee_or_member_of||Volkswagen\t\n",
      "Source:Expressions of Daily Life\t Rel:Volkswagen||org:political_religious_affiliation||communist\t\n",
      "Source:Expressions of Daily Life\t Rel:VW||org:top_members_employees||He\t\n",
      "Source:Expressions of Daily Life\t Rel:VW||org:top_members_employees||Winterkorn\t\n",
      "Source:Southern Cross\t Rel:Volkswagen||org:city_of_headquarters||Wolfsburg\t\n",
      "Source:Southern Cross\t Rel:Volkswagen||org:number_of_employees_members||70,000\t\n",
      "Source:Southern Cross\t Rel:Klaus Mohrs||per:employee_or_member_of||Volkswagen\t\n",
      "Source:Southern Cross\t Rel:he||per:employee_or_member_of||Volkswagen\t\n",
      "Source:Southern Cross\t Rel:Volkswagen||org:top_members_employees||Klaus Mohrs\t\n",
      "Source:TheBull.com.au\t Rel:Bob Merlis||per:employee_or_member_of||Volkswagen\t\n",
      "Source:Bayou Buzz\t Rel:Volkswagen||org:country_of_headquarters||Germany\t\n",
      "Source:Minneapolis Star Tribune\t Rel:VW||org:top_members_employees||he\t\n",
      "Source:Minneapolis Star Tribune\t Rel:he||per:employee_or_member_of||VW\t\n",
      "Source:Yahoo! Maktoob News\t Rel:Volkswagen||org:city_of_headquarters||FRANKFURT\t\n",
      "Source:Motoring.com.au\t Rel:VW||org:alternate_names||Volkswagen Group\t\n",
      "Source:Motoring.com.au\t Rel:Volkswagen||org:country_of_headquarters||US\t\n",
      "Source:Motoring.com.au\t Rel:VW||org:top_members_employees||Michael Horn\t\n",
      "Source:Motoring.com.au\t Rel:VW||org:stateorprovince_of_headquarters||New York\t\n",
      "Source:Motoring.com.au\t Rel:VW||org:country_of_headquarters||US\t\n",
      "Source:Motoring.com.au\t Rel:Michael Horn||per:employee_or_member_of||VW\t\n",
      "Source:Yahoo! News Australia\t Rel:VW||org:alternate_names||Volkswagen\t\n",
      "Source:Yahoo! News Australia\t Rel:Volkswagen||org:top_members_employees||Eisele\t\n",
      "Source:Take off with Natarajan\t Rel:VW||org:subsidiaries||Porsche\t\n",
      "Source:KCLU\t Rel:VW||org:top_members_employees||Mueller\t\n",
      "Source:Top Speed Cars\t Rel:Volkswagen||org:top_members_employees||Klaus Bischoff\t\n"
     ]
    }
   ],
   "source": [
    "# Input file\n",
    "in_f = 'signalmedia-1m.jsonl.gz'\n",
    "f_reader = gzip.open(in_f, 'rb') if in_f.endswith('.gz') else codecs.open(in_f, 'r', 'utf-8')\n",
    "\n",
    "# Output files\n",
    "fw_sent = codecs.open('text_for_rel.txt', 'w', 'utf-8')\n",
    "fw_rel = codecs.open('kbp_results.txt', 'w', 'utf-8')\n",
    "\n",
    "rel_res = []\n",
    "\n",
    "for line in f_reader:\n",
    "    \n",
    "    d = json.loads(line)\n",
    "    #print d['title'], d['media-type'], d['content'], d['source'], d['published'] , d['id']\n",
    "    text = re.sub(' +',' ', d['content'])    \n",
    "    sent_list = nltk.sent_tokenize(text)\n",
    "    sent_list = [sent.strip() for sent in sent_list]  \n",
    "    sent_list = [d['title']] + sent_list\n",
    "    text = ' '.join(sent_list)\n",
    "    \n",
    "    if ('Volkswagen' in text or 'volkswagen' in text ) and ('scandal' in text or 'Scandal' in text or 'emissions' in text or 'Emissions' in text ) :\n",
    "        \n",
    "        for sent in sent_list:            \n",
    "            sent = sent.encode('utf8')  \n",
    "            sent = re.sub('\\n', ' ', sent)\n",
    "            if len( sent.split() ) < 100:\n",
    "                token_list, ent_list = get_token_ner(sent)\n",
    "                \n",
    "                type_list = [ent[1] for ent in ent_list]\n",
    "                mention_list = [ent[0] for ent in ent_list]\n",
    "                \n",
    "                if 'ORGANIZATION' in type_list and 'PERSON' in type_list :\n",
    "                    fw_sent.write('%s\\n'%(' '.join(token_list)))\n",
    "                    \n",
    "                    #get relation using openie tool\n",
    "                    rel_list = get_kbp_relation(sent)\n",
    "                    \n",
    "                    if len(rel_list)>0:\n",
    "                        for rel in rel_list:\n",
    "                            #if 'Volkswagen' in rel or 'VW' in rel:\n",
    "                            if rel not in rel_res:\n",
    "                                    \n",
    "                                    rel_res.append((rel[0], rel[1], rel[2]) )\n",
    "                                    rel_res.append((rel[2], rel[1], rel[0]) )\n",
    "                                    if 'Volkswagen' in rel or 'VW' in rel:\n",
    "                                        fw_rel.write( '%s\\t%s\\t%s\\n' %(rel[0], rel[1], rel[2] ) )\n",
    "                                        print ('Source:%s\\t Rel:%s\\t' %(d['source'], '||'.join(rel) ) )\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
